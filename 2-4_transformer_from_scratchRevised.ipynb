{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"2-4_transformer_from_scratchRevised.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"P77nBWXKYFkW","colab_type":"text"},"source":["# Building the Transformer from Scratch"]},{"cell_type":"markdown","metadata":{"id":"2TzIzNXvYFkZ","colab_type":"text"},"source":["In this notebook, we'll be implementing the famous Transformer architecture from scratch.\n","\n","The code is based off of the following repos/blog posts:\n","\n","- [attention-is-all-you-need-pytorch](https://github.com/jadore801120/attention-is-all-you-need-pytorch)\n","- [nlp-tutorial](https://github.com/graykode/nlp-tutorial)\n","- [The illustrated Transformer](https://nlpinkorean.github.io/illustrated-transformer/l)\n","\n","Thanks so much to their authors!"]},{"cell_type":"code","metadata":{"id":"Fk0V1FrDYFka","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fq0T6u9sYFke","colab_type":"text"},"source":["![image](https://camo.githubusercontent.com/88e8f36ce61dedfd2491885b8df2f68c4d1f92f5/687474703a2f2f696d6775722e636f6d2f316b72463252362e706e67)"]},{"cell_type":"code","metadata":{"id":"JKA9nwqoYFkf","colab_type":"code","colab":{}},"source":["sentences = ['기분이 저기압일 때에는 고기 앞으로 가라 P', 'S eat meat when you feel low ', 'eat meat when you feel low E']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z4HLIz2nYFki","colab_type":"code","colab":{}},"source":["src_vocab = {'P' : 0, '기분이' : 1, '저기압일' : 2, '때에는' : 3, '고기' : 4, '앞으로' : 5, '가라' : 6}\n","src_vocab_size = len(src_vocab)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vjy9-cl0YFkl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":36},"outputId":"f226b3b4-49a8-41cf-c239-d288c8267277","executionInfo":{"status":"ok","timestamp":1571831961610,"user_tz":-540,"elapsed":1589,"user":{"displayName":"Seunggeun Park","photoUrl":"","userId":"17894343361302588769"}}},"source":["src_vocab"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'P': 0, '가라': 6, '고기': 4, '기분이': 1, '때에는': 3, '앞으로': 5, '저기압일': 2}"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"nuWJabtNYFko","colab_type":"code","colab":{}},"source":["tgt_vocab = {'P' : 0, 'eat' : 1, 'meat' : 2, 'when' : 3, 'you' : 4, 'feel' : 5, 'low' : 6, 'S' : 7, 'E' : 8}\n","tgt_vocab_size = len(tgt_vocab)\n","\n","src_len = 7\n","tgt_len = 7"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xkIgBV3vYFkr","colab_type":"code","colab":{}},"source":["enc_input_batch = [[src_vocab[n] for n in sentences[0].split()]]\n","dec_input_batch = [[tgt_vocab[n] for n in sentences[1].split()]]\n","dec_output_batch = [[tgt_vocab[n] for n in sentences[2].split()]]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iHw4gmSdYFku","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":73},"outputId":"adb4d41a-30ce-4d0d-9999-6b336adfbbc3","executionInfo":{"status":"ok","timestamp":1571831961615,"user_tz":-540,"elapsed":1111,"user":{"displayName":"Seunggeun Park","photoUrl":"","userId":"17894343361302588769"}}},"source":["print(enc_input_batch)\n","print(dec_input_batch)\n","print(dec_output_batch)"],"execution_count":35,"outputs":[{"output_type":"stream","text":["[[1, 2, 3, 4, 5, 6, 0]]\n","[[7, 1, 2, 3, 4, 5, 6]]\n","[[1, 2, 3, 4, 5, 6, 8]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MqESjo7-YFkx","colab_type":"code","colab":{}},"source":["from torch.autograd import Variable"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aYjjyGmRYFk0","colab_type":"code","colab":{}},"source":["enc_input_batch = Variable(torch.LongTensor(enc_input_batch))\n","dec_input_batch = Variable(torch.LongTensor(dec_input_batch))\n","dec_output_batch = Variable(torch.LongTensor(dec_output_batch))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"w3ZsYUOkYFk2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":73},"outputId":"c1e46374-c4d9-4c44-9ed6-558ea28a0922","executionInfo":{"status":"ok","timestamp":1571831962213,"user_tz":-540,"elapsed":1332,"user":{"displayName":"Seunggeun Park","photoUrl":"","userId":"17894343361302588769"}}},"source":["print(enc_input_batch)\n","print(dec_input_batch)\n","print(dec_output_batch)"],"execution_count":38,"outputs":[{"output_type":"stream","text":["tensor([[1, 2, 3, 4, 5, 6, 0]])\n","tensor([[7, 1, 2, 3, 4, 5, 6]])\n","tensor([[1, 2, 3, 4, 5, 6, 8]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"N0woOLGvYFk4","colab_type":"code","colab":{}},"source":["import math"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nyAKzlgZYFk6","colab_type":"code","colab":{}},"source":["#positional embedding을 구현하는 클래스\n","\n","class PositionalEmbedding(nn.Module):\n","    def __init__(self, d_model, max_len=512):\n","        super().__init__()        \n","        # Compute the positional encodings once in log space.\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len).unsqueeze(1).float()\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(0)\n","        self.weight = nn.Parameter(pe, requires_grad=False)\n","        \n","    def forward(self, x):\n","        return self.weight[:, :x.size(1), :] # (1, Seq, Feature)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4anyqpESYFk8","colab_type":"code","colab":{}},"source":["class WordPositionEmbedding(nn.Module):\n","    def __init__(self, vocab_size, d_model=512):\n","        super().__init__()\n","        self.word_embedding = nn.Embedding(vocab_size, d_model)\n","        self.position_embedding = PositionalEmbedding(d_model)\n","        \n","    def forward(self, x, mask=None):\n","        return self.word_embedding(x) + self.position_embedding(x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ngm-B5MWYFk-","colab_type":"code","colab":{}},"source":["input_emb = WordPositionEmbedding(src_vocab_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WsMTioyLYFlA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":92},"outputId":"9ae9ffd3-f628-45e9-bd99-e91158b11958","executionInfo":{"status":"ok","timestamp":1571831962689,"user_tz":-540,"elapsed":1095,"user":{"displayName":"Seunggeun Park","photoUrl":"","userId":"17894343361302588769"}}},"source":["input_emb"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["WordPositionEmbedding(\n","  (word_embedding): Embedding(7, 512)\n","  (position_embedding): PositionalEmbedding()\n",")"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"code","metadata":{"id":"cSM6bW_tYFlD","colab_type":"code","colab":{}},"source":["enc_emb = input_emb(enc_input_batch)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mIGX1HWrYFlF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":36},"outputId":"b6f509b1-d289-468e-9b00-c0c5c96cec41","executionInfo":{"status":"ok","timestamp":1571831962692,"user_tz":-540,"elapsed":855,"user":{"displayName":"Seunggeun Park","photoUrl":"","userId":"17894343361302588769"}}},"source":["enc_emb.shape"],"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 7, 512])"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"markdown","metadata":{"id":"cZtoTBnrYFlH","colab_type":"text"},"source":["![image](https://camo.githubusercontent.com/88e8f36ce61dedfd2491885b8df2f68c4d1f92f5/687474703a2f2f696d6775722e636f6d2f316b72463252362e706e67)"]},{"cell_type":"code","metadata":{"id":"5ZKsU-hQYFlI","colab_type":"code","colab":{}},"source":["class TransformerEncoder(nn.Module):\n","    def __init__(self, n_blocks=6, d_model=512, n_heads=8, d_ff=2048, dropout=0.1):\n","        super().__init__()\n","        \n","        self.encoders = nn.ModuleList([\n","            EncoderBlock(d_model=d_model, d_feature=d_model // n_heads, d_ff=d_ff, dropout=dropout)\n","                                                                                                                    for _ in range(n_blocks)])\n","    \n","    def forward(self, x, mask=None):\n","        for encoder in self.encoders:\n","            x = encoder(x)\n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wq-V4QpGYFlK","colab_type":"text"},"source":["```python\n","encoder = TransformerEncoder()\n","enc_output_batch = encoder(enc_emb)\n","```"]},{"cell_type":"code","metadata":{"id":"twpR96IGYFlK","colab_type":"code","colab":{}},"source":["class EncoderBlock(nn.Module):\n","    def __init__(self, d_model=512, d_feature=64, d_ff=2048, n_heads=8, dropout=0.1):\n","        super().__init__()\n","        self.attn_head = MultiHeadAttention(d_model, d_feature, n_heads, dropout)\n","        self.layer_norm1 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","        \n","        self.position_wise_feed_forward = nn.Sequential(\n","            nn.Linear(d_model, d_ff),\n","            nn.ReLU(),\n","            nn.Linear(d_ff, d_model),\n","        )\n","        self.layer_norm2 = nn.LayerNorm(d_model)\n","        \n","    def forward(self, x, mask=None):\n","        print('[Encoder Block]')\n","        print(x.shape, \"Encoder block input\")\n","        att = self.attn_head(x, x, x, mask=mask)\n","        print(att.shape, \"Attention output\")\n","        \n","        # Apply normalization and residual connection\n","        x = self.dropout(self.layer_norm1(x + att))\n","        \n","        # Apply position-wise feedforward network\n","        pos = self.position_wise_feed_forward(x)\n","        print(pos.shape, \"Feedforward output\")\n","        \n","        # Apply normalization and residual connection\n","        x = self.dropout(self.layer_norm2(x + pos))\n","        print(x.shape, \"Encoder output\\n\")\n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QBfxRUUlYFlO","colab_type":"code","colab":{}},"source":["class MultiHeadAttention(nn.Module):\n","    def __init__(self, d_model, d_feature, n_heads, dropout=0.1):\n","        super().__init__()\n","        self.d_model = d_model\n","        self.n_heads = n_heads\n","        self.d_feature = d_feature\n","        \n","        self.W_Q = nn.Linear(d_model, d_feature * n_heads)\n","        self.W_K = nn.Linear(d_model, d_feature * n_heads)\n","        self.W_V = nn.Linear(d_model, d_feature * n_heads)\n","        \n","        self.W_O = nn.Linear(n_heads * d_feature, d_model)\n","        \n","    def forward(self, x1, x2, x3, mask):\n","        print('\\t[MULTIHEAD]')\n","        # q: [batch_size x len_q x d_model], k: [batch_size x len_k x d_model], v: [batch_size x len_k x d_model]\n","        residual, batch_size = x1, x1.size(0)\n","        \n","        # (B, S, D) -proj-> (B, S, D) -split-> (B, S, H, W) -trans-> (B, H, S, W)\n","        Q = self.W_Q(x1).view(batch_size, -1, self.n_heads, self.d_feature).transpose(1,2)  # q_s: [batch_size x n_heads x len_q x d_k]\n","        K = self.W_K(x2).view(batch_size, -1, self.n_heads, self.d_feature).transpose(1,2)  # k_s: [batch_size x n_heads x len_k x d_k]\n","        V = self.W_V(x3).view(batch_size, -1, self.n_heads, self.d_feature).transpose(1,2)  # v_s: [batch_size x n_heads x len_k x d_v]\n","        print('\\t# Q, K, V shape(batch, heads, length, d_model/heads) :')\n","        print('\\t',Q.shape, K.shape, V.shape)\n","        if mask is not None:\n","            mask = mask.unsqueeze(1).repeat(1, self.n_heads, 1, 1) # attn_mask : [batch_size x n_heads x len_q x len_k]\n","\n","        # context: [batch_size x n_heads x len_q x d_v], attn: [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n","        Z = ScaledDotProductAttention()(Q, K, V, mask, self.d_feature)\n","        print('\\t# Z shape : ', Z.shape)\n","        Z = Z.transpose(1, 2).contiguous().view(batch_size, -1, self.n_heads * self.d_feature) # context: [batch_size x len_q x n_heads * d_v]\n","        print('\\t# Z shape changed : ', Z.shape)\n","        output = self.W_O(Z)\n","        return output # output: [batch_size x len_q x d_model]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PpvoolMKYFlT","colab_type":"text"},"source":["$$ \\textrm{Attention}(Q, K, V) = \\textrm{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V $$"]},{"cell_type":"code","metadata":{"id":"QkvK5_BOYFlV","colab_type":"code","colab":{}},"source":["class ScaledDotProductAttention(nn.Module):\n","    def __init__(self):\n","        super(ScaledDotProductAttention, self).__init__()\n","        \n","    def forward(self, Q, K, V, attn_mask, d_k):\n","        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k) # scores : [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n","        print('\\t# scores, V : ', scores.shape, V.shape)\n","        if attn_mask is not None:\n","            scores.masked_fill_(attn_mask, -1e9) # Fills elements of self tensor with value where mask is one.\n","        attn = nn.Softmax(dim=-1)(scores)\n","        context = torch.matmul(attn, V)\n","        return context"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"w1eys8Xzc8HJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":36},"outputId":"d41a57ca-9742-4023-f1a9-ba3d8e1d17d9","executionInfo":{"status":"ok","timestamp":1571831964844,"user_tz":-540,"elapsed":580,"user":{"displayName":"Seunggeun Park","photoUrl":"","userId":"17894343361302588769"}}},"source":["enc_emb.shape"],"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 7, 512])"]},"metadata":{"tags":[]},"execution_count":50}]},{"cell_type":"code","metadata":{"id":"7UrgUDRTYFlX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"4183f9de-969a-4d99-e120-439f32ec9d0c","executionInfo":{"status":"ok","timestamp":1571831965117,"user_tz":-540,"elapsed":688,"user":{"displayName":"Seunggeun Park","photoUrl":"","userId":"17894343361302588769"}}},"source":["encoder = TransformerEncoder()\n","enc_output_batch = encoder(enc_emb)"],"execution_count":51,"outputs":[{"output_type":"stream","text":["[Encoder Block]\n","torch.Size([1, 7, 512]) Encoder block input\n","\t[MULTIHEAD]\n","\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n","\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n","\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n","\t# Z shape :  torch.Size([1, 8, 7, 64])\n","\t# Z shape changed :  torch.Size([1, 7, 512])\n","torch.Size([1, 7, 512]) Attention output\n","torch.Size([1, 7, 512]) Feedforward output\n","torch.Size([1, 7, 512]) Encoder output\n","\n","[Encoder Block]\n","torch.Size([1, 7, 512]) Encoder block input\n","\t[MULTIHEAD]\n","\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n","\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n","\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n","\t# Z shape :  torch.Size([1, 8, 7, 64])\n","\t# Z shape changed :  torch.Size([1, 7, 512])\n","torch.Size([1, 7, 512]) Attention output\n","torch.Size([1, 7, 512]) Feedforward output\n","torch.Size([1, 7, 512]) Encoder output\n","\n","[Encoder Block]\n","torch.Size([1, 7, 512]) Encoder block input\n","\t[MULTIHEAD]\n","\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n","\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n","\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n","\t# Z shape :  torch.Size([1, 8, 7, 64])\n","\t# Z shape changed :  torch.Size([1, 7, 512])\n","torch.Size([1, 7, 512]) Attention output\n","torch.Size([1, 7, 512]) Feedforward output\n","torch.Size([1, 7, 512]) Encoder output\n","\n","[Encoder Block]\n","torch.Size([1, 7, 512]) Encoder block input\n","\t[MULTIHEAD]\n","\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n","\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n","\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n","\t# Z shape :  torch.Size([1, 8, 7, 64])\n","\t# Z shape changed :  torch.Size([1, 7, 512])\n","torch.Size([1, 7, 512]) Attention output\n","torch.Size([1, 7, 512]) Feedforward output\n","torch.Size([1, 7, 512]) Encoder output\n","\n","[Encoder Block]\n","torch.Size([1, 7, 512]) Encoder block input\n","\t[MULTIHEAD]\n","\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n","\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n","\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n","\t# Z shape :  torch.Size([1, 8, 7, 64])\n","\t# Z shape changed :  torch.Size([1, 7, 512])\n","torch.Size([1, 7, 512]) Attention output\n","torch.Size([1, 7, 512]) Feedforward output\n","torch.Size([1, 7, 512]) Encoder output\n","\n","[Encoder Block]\n","torch.Size([1, 7, 512]) Encoder block input\n","\t[MULTIHEAD]\n","\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n","\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n","\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n","\t# Z shape :  torch.Size([1, 8, 7, 64])\n","\t# Z shape changed :  torch.Size([1, 7, 512])\n","torch.Size([1, 7, 512]) Attention output\n","torch.Size([1, 7, 512]) Feedforward output\n","torch.Size([1, 7, 512]) Encoder output\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HiYoBjdyYFlZ","colab_type":"code","colab":{}},"source":["class TransformerDecoder(nn.Module):\n","    def __init__(self, n_blocks=6, d_model=512, d_feature=64,\n","                 d_ff=2048, n_heads=8, dropout=0.1):\n","        super().__init__()\n","        self.position_embedding = PositionalEmbedding(d_model)\n","        self.decoders = nn.ModuleList([\n","            DecoderBlock(d_model=d_model, d_feature=d_model // n_heads, d_ff=d_ff, dropout=dropout)\n","            for _ in range(n_blocks)\n","        ])\n","        \n","    def forward(self, x, enc_out, src_mask=None, tgt_mask=None):\n","        for decoder in self.decoders:\n","            x = decoder(x, enc_out, src_mask=src_mask, tgt_mask=tgt_mask)\n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0FFmrc9IYFlb","colab_type":"code","colab":{}},"source":["class DecoderBlock(nn.Module):\n","    def __init__(self, d_model=512, d_feature=64, d_ff=2048, n_heads=8, dropout=0.1):\n","        super().__init__()\n","        self.enc_attn_head = MultiHeadAttention(d_model, d_feature, n_heads, dropout)\n","        self.dec_attn_head = MultiHeadAttention(d_model, d_feature, n_heads, dropout)\n","        self.position_wise_feed_forward = nn.Sequential(\n","            nn.Linear(d_model, d_ff),\n","            nn.ReLU(),\n","            nn.Linear(d_ff, d_model),\n","        )\n","\n","        self.layer_norm1 = nn.LayerNorm(d_model)\n","        self.layer_norm2 = nn.LayerNorm(d_model)\n","        self.layer_norm3 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, x, enc_out, src_mask=None, tgt_mask=None):\n","        # Apply attention to inputs\n","        print('[Decoder Block]')\n","        print(x.shape, \"Decoder block input\")\n","        att = self.dec_attn_head(x, x, x, mask=src_mask)\n","        print(att.shape, \"First Attention output\")\n","        x = self.dropout(self.layer_norm1(x + att))\n","        \n","        # Apply attention to the encoder outputs and outputs of the previous layer\n","        att = self.dec_attn_head(x1=x, x2=enc_out, x3=enc_out, mask=tgt_mask)\n","        print(att.shape, \"Second Attention output\")\n","        x = self.dropout(self.layer_norm2(x + att))\n","        # Apply position-wise feedforward network\n","        pos = self.position_wise_feed_forward(x)\n","        print(pos.shape, \"Feedforward output\")\n","        x = self.dropout(self.layer_norm2(x + pos))\n","        print(x.shape, \"Decoder output\\n\")\n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UpMruoE1YFld","colab_type":"code","colab":{}},"source":["output_emb = WordPositionEmbedding(tgt_vocab_size)\n","decoder = TransformerDecoder()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jn38cefMYFlf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"865cf703-4658-4fda-b02c-19ba9da66ad1","executionInfo":{"status":"ok","timestamp":1571831969837,"user_tz":-540,"elapsed":811,"user":{"displayName":"Seunggeun Park","photoUrl":"","userId":"17894343361302588769"}}},"source":["dec_emb = output_emb(dec_input_batch)\n","result = decoder(dec_emb, enc_output_batch)"],"execution_count":55,"outputs":[{"output_type":"stream","text":["[Decoder Block]\n","torch.Size([1, 7, 512]) Decoder block input\n","\t[MULTIHEAD]\n","\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n","\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n","\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n","\t# Z shape :  torch.Size([1, 8, 7, 64])\n","\t# Z shape changed :  torch.Size([1, 7, 512])\n","torch.Size([1, 7, 512]) First Attention output\n","\t[MULTIHEAD]\n","\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n","\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n","\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n","\t# Z shape :  torch.Size([1, 8, 7, 64])\n","\t# Z shape changed :  torch.Size([1, 7, 512])\n","torch.Size([1, 7, 512]) Second Attention output\n","torch.Size([1, 7, 512]) Feedforward output\n","torch.Size([1, 7, 512]) Decoder output\n","\n","[Decoder Block]\n","torch.Size([1, 7, 512]) Decoder block input\n","\t[MULTIHEAD]\n","\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n","\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n","\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n","\t# Z shape :  torch.Size([1, 8, 7, 64])\n","\t# Z shape changed :  torch.Size([1, 7, 512])\n","torch.Size([1, 7, 512]) First Attention output\n","\t[MULTIHEAD]\n","\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n","\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n","\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n","\t# Z shape :  torch.Size([1, 8, 7, 64])\n","\t# Z shape changed :  torch.Size([1, 7, 512])\n","torch.Size([1, 7, 512]) Second Attention output\n","torch.Size([1, 7, 512]) Feedforward output\n","torch.Size([1, 7, 512]) Decoder output\n","\n","[Decoder Block]\n","torch.Size([1, 7, 512]) Decoder block input\n","\t[MULTIHEAD]\n","\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n","\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n","\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n","\t# Z shape :  torch.Size([1, 8, 7, 64])\n","\t# Z shape changed :  torch.Size([1, 7, 512])\n","torch.Size([1, 7, 512]) First Attention output\n","\t[MULTIHEAD]\n","\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n","\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n","\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n","\t# Z shape :  torch.Size([1, 8, 7, 64])\n","\t# Z shape changed :  torch.Size([1, 7, 512])\n","torch.Size([1, 7, 512]) Second Attention output\n","torch.Size([1, 7, 512]) Feedforward output\n","torch.Size([1, 7, 512]) Decoder output\n","\n","[Decoder Block]\n","torch.Size([1, 7, 512]) Decoder block input\n","\t[MULTIHEAD]\n","\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n","\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n","\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n","\t# Z shape :  torch.Size([1, 8, 7, 64])\n","\t# Z shape changed :  torch.Size([1, 7, 512])\n","torch.Size([1, 7, 512]) First Attention output\n","\t[MULTIHEAD]\n","\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n","\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n","\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n","\t# Z shape :  torch.Size([1, 8, 7, 64])\n","\t# Z shape changed :  torch.Size([1, 7, 512])\n","torch.Size([1, 7, 512]) Second Attention output\n","torch.Size([1, 7, 512]) Feedforward output\n","torch.Size([1, 7, 512]) Decoder output\n","\n","[Decoder Block]\n","torch.Size([1, 7, 512]) Decoder block input\n","\t[MULTIHEAD]\n","\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n","\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n","\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n","\t# Z shape :  torch.Size([1, 8, 7, 64])\n","\t# Z shape changed :  torch.Size([1, 7, 512])\n","torch.Size([1, 7, 512]) First Attention output\n","\t[MULTIHEAD]\n","\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n","\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n","\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n","\t# Z shape :  torch.Size([1, 8, 7, 64])\n","\t# Z shape changed :  torch.Size([1, 7, 512])\n","torch.Size([1, 7, 512]) Second Attention output\n","torch.Size([1, 7, 512]) Feedforward output\n","torch.Size([1, 7, 512]) Decoder output\n","\n","[Decoder Block]\n","torch.Size([1, 7, 512]) Decoder block input\n","\t[MULTIHEAD]\n","\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n","\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n","\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n","\t# Z shape :  torch.Size([1, 8, 7, 64])\n","\t# Z shape changed :  torch.Size([1, 7, 512])\n","torch.Size([1, 7, 512]) First Attention output\n","\t[MULTIHEAD]\n","\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n","\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n","\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n","\t# Z shape :  torch.Size([1, 8, 7, 64])\n","\t# Z shape changed :  torch.Size([1, 7, 512])\n","torch.Size([1, 7, 512]) Second Attention output\n","torch.Size([1, 7, 512]) Feedforward output\n","torch.Size([1, 7, 512]) Decoder output\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4UOWqzmkYFlh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":36},"outputId":"bf18bd25-6474-44d2-aa08-dc0671f4a44e","executionInfo":{"status":"ok","timestamp":1571831969839,"user_tz":-540,"elapsed":555,"user":{"displayName":"Seunggeun Park","photoUrl":"","userId":"17894343361302588769"}}},"source":["result.shape"],"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 7, 512])"]},"metadata":{"tags":[]},"execution_count":56}]},{"cell_type":"markdown","metadata":{"id":"4Gnl8G1_YFll","colab_type":"text"},"source":["------------"]},{"cell_type":"code","metadata":{"id":"_V1ZdypxYFlm","colab_type":"code","colab":{}},"source":["def get_attn_pad_mask(seq_q, seq_k):\n","    batch_size, len_q = seq_q.size()\n","    batch_size, len_k = seq_k.size()\n","    # eq(zero) is PAD token\n","    pad_attn_mask = seq_k.data.eq(0).unsqueeze(1)  # batch_size x 1 x len_k(=len_q), one is masking\n","    return pad_attn_mask.expand(batch_size, len_q, len_k)  # batch_size x len_q x len_k"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3e69AMBlYFlp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":167},"outputId":"ee35456b-03e2-4385-b07b-db7aee3ee6d3","executionInfo":{"status":"ok","timestamp":1571833095082,"user_tz":-540,"elapsed":1292,"user":{"displayName":"Seunggeun Park","photoUrl":"","userId":"17894343361302588769"}}},"source":["enc_self_attn_mask = get_attn_pad_mask(enc_input_batch, enc_input_batch)\n","print(enc_self_attn_mask.shape)\n","print(enc_self_attn_mask)"],"execution_count":59,"outputs":[{"output_type":"stream","text":["torch.Size([1, 7, 7])\n","tensor([[[False, False, False, False, False, False,  True],\n","         [False, False, False, False, False, False,  True],\n","         [False, False, False, False, False, False,  True],\n","         [False, False, False, False, False, False,  True],\n","         [False, False, False, False, False, False,  True],\n","         [False, False, False, False, False, False,  True],\n","         [False, False, False, False, False, False,  True]]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"z7AJDm5hYFls","colab_type":"code","colab":{}},"source":["def get_attn_subsequent_mask(seq):\n","    attn_shape = [seq.size(0), seq.size(1), seq.size(1)]\n","    subsequent_mask = np.triu(np.ones(attn_shape), k=1)\n","    subsequent_mask = torch.from_numpy(subsequent_mask).byte()\n","    return subsequent_mask"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qy7Vc7EZYFlw","colab_type":"code","colab":{}},"source":["dec_self_attn_pad_mask = get_attn_pad_mask(dec_input_batch, dec_input_batch)\n","dec_self_attn_subsequent_mask = get_attn_subsequent_mask(dec_input_batch)\n","dec_self_attn_mask = torch.gt((dec_self_attn_pad_mask + dec_self_attn_subsequent_mask), 0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8oruTIDGYFly","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":167},"outputId":"d71ba5b7-553e-4c8d-f82c-f1b1e58d21df","executionInfo":{"status":"ok","timestamp":1571833095093,"user_tz":-540,"elapsed":796,"user":{"displayName":"Seunggeun Park","photoUrl":"","userId":"17894343361302588769"}}},"source":["print(dec_self_attn_pad_mask.shape)\n","print(dec_self_attn_pad_mask)"],"execution_count":62,"outputs":[{"output_type":"stream","text":["torch.Size([1, 7, 7])\n","tensor([[[False, False, False, False, False, False, False],\n","         [False, False, False, False, False, False, False],\n","         [False, False, False, False, False, False, False],\n","         [False, False, False, False, False, False, False],\n","         [False, False, False, False, False, False, False],\n","         [False, False, False, False, False, False, False],\n","         [False, False, False, False, False, False, False]]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pfUHKPNKYFl2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":167},"outputId":"1c5c8a8e-242e-43b9-aeb9-752b4e440bcf","executionInfo":{"status":"ok","timestamp":1571833095094,"user_tz":-540,"elapsed":629,"user":{"displayName":"Seunggeun Park","photoUrl":"","userId":"17894343361302588769"}}},"source":["print(dec_self_attn_subsequent_mask.shape)\n","print(dec_self_attn_subsequent_mask)"],"execution_count":63,"outputs":[{"output_type":"stream","text":["torch.Size([1, 7, 7])\n","tensor([[[0, 1, 1, 1, 1, 1, 1],\n","         [0, 0, 1, 1, 1, 1, 1],\n","         [0, 0, 0, 1, 1, 1, 1],\n","         [0, 0, 0, 0, 1, 1, 1],\n","         [0, 0, 0, 0, 0, 1, 1],\n","         [0, 0, 0, 0, 0, 0, 1],\n","         [0, 0, 0, 0, 0, 0, 0]]], dtype=torch.uint8)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_WQPiY1jYFl5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":148},"outputId":"5de3cae3-88d0-4bd5-e278-35e53fbbfec1","executionInfo":{"status":"ok","timestamp":1571833095743,"user_tz":-540,"elapsed":951,"user":{"displayName":"Seunggeun Park","photoUrl":"","userId":"17894343361302588769"}}},"source":["print(dec_self_attn_mask)"],"execution_count":64,"outputs":[{"output_type":"stream","text":["tensor([[[False,  True,  True,  True,  True,  True,  True],\n","         [False, False,  True,  True,  True,  True,  True],\n","         [False, False, False,  True,  True,  True,  True],\n","         [False, False, False, False,  True,  True,  True],\n","         [False, False, False, False, False,  True,  True],\n","         [False, False, False, False, False, False,  True],\n","         [False, False, False, False, False, False, False]]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"b_hP91VqYFl8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"481b9294-c846-4832-f12c-227adefa2570","executionInfo":{"status":"ok","timestamp":1571833096250,"user_tz":-540,"elapsed":1256,"user":{"displayName":"Seunggeun Park","photoUrl":"","userId":"17894343361302588769"}}},"source":["encoder = TransformerEncoder()\n","enc_output_batch = encoder(enc_emb, enc_self_attn_mask)\n","\n","output_emb = WordPositionEmbedding(tgt_vocab_size)\n","decoder = TransformerDecoder()\n","\n","dec_emb = output_emb(dec_input_batch)\n","result = decoder(dec_emb, enc_output_batch, src_mask=enc_self_attn_mask, tgt_mask= dec_self_attn_mask)"],"execution_count":65,"outputs":[{"output_type":"stream","text":["[Encoder Block]\n","torch.Size([1, 7, 512]) Encoder block input\n","\t[MULTIHEAD]\n","\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n","\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n","\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n","\t# Z shape :  torch.Size([1, 8, 7, 64])\n","\t# Z shape changed :  torch.Size([1, 7, 512])\n","torch.Size([1, 7, 512]) Attention output\n","torch.Size([1, 7, 512]) Feedforward output\n","torch.Size([1, 7, 512]) Encoder output\n","\n","[Encoder Block]\n","torch.Size([1, 7, 512]) Encoder block input\n","\t[MULTIHEAD]\n","\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n","\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n","\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n","\t# Z shape :  torch.Size([1, 8, 7, 64])\n","\t# Z shape changed :  torch.Size([1, 7, 512])\n","torch.Size([1, 7, 512]) Attention output\n","torch.Size([1, 7, 512]) Feedforward output\n","torch.Size([1, 7, 512]) Encoder output\n","\n","[Encoder Block]\n","torch.Size([1, 7, 512]) Encoder block input\n","\t[MULTIHEAD]\n","\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n","\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n","\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n","\t# Z shape :  torch.Size([1, 8, 7, 64])\n","\t# Z shape changed :  torch.Size([1, 7, 512])\n","torch.Size([1, 7, 512]) Attention output\n","torch.Size([1, 7, 512]) Feedforward output\n","torch.Size([1, 7, 512]) Encoder output\n","\n","[Encoder Block]\n","torch.Size([1, 7, 512]) Encoder block input\n","\t[MULTIHEAD]\n","\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n","\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n","\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n","\t# Z shape :  torch.Size([1, 8, 7, 64])\n","\t# Z shape changed :  torch.Size([1, 7, 512])\n","torch.Size([1, 7, 512]) Attention output\n","torch.Size([1, 7, 512]) Feedforward output\n","torch.Size([1, 7, 512]) Encoder output\n","\n","[Encoder Block]\n","torch.Size([1, 7, 512]) Encoder block input\n","\t[MULTIHEAD]\n","\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n","\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n","\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n","\t# Z shape :  torch.Size([1, 8, 7, 64])\n","\t# Z shape changed :  torch.Size([1, 7, 512])\n","torch.Size([1, 7, 512]) Attention output\n","torch.Size([1, 7, 512]) Feedforward output\n","torch.Size([1, 7, 512]) Encoder output\n","\n","[Encoder Block]\n","torch.Size([1, 7, 512]) Encoder block input\n","\t[MULTIHEAD]\n","\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n","\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n","\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n","\t# Z shape :  torch.Size([1, 8, 7, 64])\n","\t# Z shape changed :  torch.Size([1, 7, 512])\n","torch.Size([1, 7, 512]) Attention output\n","torch.Size([1, 7, 512]) Feedforward output\n","torch.Size([1, 7, 512]) Encoder output\n","\n","[Decoder Block]\n","torch.Size([1, 7, 512]) Decoder block input\n","\t[MULTIHEAD]\n","\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n","\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n","\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n","\t# Z shape :  torch.Size([1, 8, 7, 64])\n","\t# Z shape changed :  torch.Size([1, 7, 512])\n","torch.Size([1, 7, 512]) First Attention output\n","\t[MULTIHEAD]\n","\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n","\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n","\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n","\t# Z shape :  torch.Size([1, 8, 7, 64])\n","\t# Z shape changed :  torch.Size([1, 7, 512])\n","torch.Size([1, 7, 512]) Second Attention output\n","torch.Size([1, 7, 512]) Feedforward output\n","torch.Size([1, 7, 512]) Decoder output\n","\n","[Decoder Block]\n","torch.Size([1, 7, 512]) Decoder block input\n","\t[MULTIHEAD]\n","\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n","\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n","\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n","\t# Z shape :  torch.Size([1, 8, 7, 64])\n","\t# Z shape changed :  torch.Size([1, 7, 512])\n","torch.Size([1, 7, 512]) First Attention output\n","\t[MULTIHEAD]\n","\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n","\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n","\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n","\t# Z shape :  torch.Size([1, 8, 7, 64])\n","\t# Z shape changed :  torch.Size([1, 7, 512])\n","torch.Size([1, 7, 512]) Second Attention output\n","torch.Size([1, 7, 512]) Feedforward output\n","torch.Size([1, 7, 512]) Decoder output\n","\n","[Decoder Block]\n","torch.Size([1, 7, 512]) Decoder block input\n","\t[MULTIHEAD]\n","\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n","\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n","\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n","\t# Z shape :  torch.Size([1, 8, 7, 64])\n","\t# Z shape changed :  torch.Size([1, 7, 512])\n","torch.Size([1, 7, 512]) First Attention output\n","\t[MULTIHEAD]\n","\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n","\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n","\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n","\t# Z shape :  torch.Size([1, 8, 7, 64])\n","\t# Z shape changed :  torch.Size([1, 7, 512])\n","torch.Size([1, 7, 512]) Second Attention output\n","torch.Size([1, 7, 512]) Feedforward output\n","torch.Size([1, 7, 512]) Decoder output\n","\n","[Decoder Block]\n","torch.Size([1, 7, 512]) Decoder block input\n","\t[MULTIHEAD]\n","\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n","\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n","\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n","\t# Z shape :  torch.Size([1, 8, 7, 64])\n","\t# Z shape changed :  torch.Size([1, 7, 512])\n","torch.Size([1, 7, 512]) First Attention output\n","\t[MULTIHEAD]\n","\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n","\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n","\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n","\t# Z shape :  torch.Size([1, 8, 7, 64])\n","\t# Z shape changed :  torch.Size([1, 7, 512])\n","torch.Size([1, 7, 512]) Second Attention output\n","torch.Size([1, 7, 512]) Feedforward output\n","torch.Size([1, 7, 512]) Decoder output\n","\n","[Decoder Block]\n","torch.Size([1, 7, 512]) Decoder block input\n","\t[MULTIHEAD]\n","\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n","\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n","\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n","\t# Z shape :  torch.Size([1, 8, 7, 64])\n","\t# Z shape changed :  torch.Size([1, 7, 512])\n","torch.Size([1, 7, 512]) First Attention output\n","\t[MULTIHEAD]\n","\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n","\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n","\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n","\t# Z shape :  torch.Size([1, 8, 7, 64])\n","\t# Z shape changed :  torch.Size([1, 7, 512])\n","torch.Size([1, 7, 512]) Second Attention output\n","torch.Size([1, 7, 512]) Feedforward output\n","torch.Size([1, 7, 512]) Decoder output\n","\n","[Decoder Block]\n","torch.Size([1, 7, 512]) Decoder block input\n","\t[MULTIHEAD]\n","\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n","\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n","\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n","\t# Z shape :  torch.Size([1, 8, 7, 64])\n","\t# Z shape changed :  torch.Size([1, 7, 512])\n","torch.Size([1, 7, 512]) First Attention output\n","\t[MULTIHEAD]\n","\t# Q, K, V shape(batch, heads, length, d_model/heads) :\n","\t torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64]) torch.Size([1, 8, 7, 64])\n","\t# scores, V :  torch.Size([1, 8, 7, 7]) torch.Size([1, 8, 7, 64])\n","\t# Z shape :  torch.Size([1, 8, 7, 64])\n","\t# Z shape changed :  torch.Size([1, 7, 512])\n","torch.Size([1, 7, 512]) Second Attention output\n","torch.Size([1, 7, 512]) Feedforward output\n","torch.Size([1, 7, 512]) Decoder output\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Yz6teShrYFl-","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}